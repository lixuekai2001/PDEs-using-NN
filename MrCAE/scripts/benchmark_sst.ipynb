{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark: sea surface temperature"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. We benchmark against the number of parameters / size of hidden representations of other similar networks.\n",
    "2. These other networks include:\n",
    "    a. The same multilevel CAE with nonlinear activations (but without progressive refinements).\n",
    "    b. Linear CAE with symmetric skipped connections.\n",
    "    c. CAE with symmetric skipped connections & nonlinear activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../src/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import torch_cae_multilevel_V4 as net\n",
    "import torch_cae_skip_connection as net2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_path = '../data/npy/sst.mnmean.mask2.npy'\n",
    "map_path = '../data/npy/mask_w1.npy'\n",
    "\n",
    "dataset = net.MultiScaleDynamicsDataSet(data_path, n_levels=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multilevel CAE with progressive refinements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archs = [[1,3,5,7],[1,5,9,13],[1,9,17,25],[1,17,33,49]]\n",
    "tols = [0.05, 0.03, 0.02, 0.01]\n",
    "net.train_net(archs=archs, dataset=dataset, max_epoch=4000, batch_size=350, tols=tols, activation=torch.nn.Sequential(), \n",
    "              w=0.5, model_path=model_path, result_path=result_path, std=0.01, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_path = '../result/sst'\n",
    "# results_1 = {}\n",
    "# for file_name in sorted(os.listdir(result_path)):\n",
    "#     if file_name.endswith('.dat'):\n",
    "#         key, _ = file_name.split('.')\n",
    "#         with open(os.path.join(result_path, file_name), 'rb') as f: \n",
    "#             records[key]= pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multilevel CAE with nonlinear activation functions (without progressive refinements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = results_1['arch']\n",
    "results_2 = net.train_net(arch=arch, dataset=dataset, max_epoch=5000, batch_size=315, tols=None,\n",
    "                          activation=torch.nn.ReLU(),  w=0.9, std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAE with symmetric skipped connections & nonlinear activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = results_1['arch']\n",
    "n_params_3, errs_3 = net2.train_archs(arch=arch, activation=torch.nn.ReLU(), dataset=dataset, \n",
    "                                      base_epoch=5000, batch_size=315, w=0.9, std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear CAE with symmetric skipped connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = results_1['arch']\n",
    "n_params_4, errs_4 = net2.train_archs(arch=arch, activation=torch.nn.Sequential(), dataset=dataset, \n",
    "                                      base_epoch=5000, batch_size=315, w=0.9, std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### err - # of params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(np.log(results_1['n_params']), np.log(results_1['best_val_errs']), 'r-o', markersize=10, linewidth=2.0)\n",
    "plt.plot(np.log(results_2['n_params']), np.log(results_2['best_val_errs']), 'b-o', markersize=10, linewidth=2.0)\n",
    "plt.plot(np.log(n_params_3), np.log(errs_3), 'g-o', markersize=10, linewidth=2.0)\n",
    "plt.plot(np.log(n_params_4), np.log(errs_4), 'c-o', markersize=10, linewidth=2.0)\n",
    "plt.xlabel('log(number of parameters)', fontsize=20)\n",
    "plt.ylabel('log(validation error)', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### err - # of encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the size of encodings\n",
    "arch_diff = list()\n",
    "for l in arch:\n",
    "    arch_diff.append([1] + [l[i] - l[i-1] for i in range(1, len(l))])\n",
    "\n",
    "size_of_maps = list()\n",
    "for i in range(len(arch)):\n",
    "    size_of_maps.append([np.multiply(*results_1['model'].resolved_maps[str(i)]['0'].size())])\n",
    "    for j in range(len(results_1['model'].resolved_maps[str(i)]) - 1):\n",
    "        n1 = int(torch.sum(1 - results_1['model'].resolved_maps[str(i)][str(j)]))\n",
    "        size_of_maps[i].append(n1)\n",
    "\n",
    "n_encodings_1 = [0]\n",
    "n_encodings_234 = [0]\n",
    "for i in range(len(arch_diff)):\n",
    "    n_encodings_1.append(n_encodings_1[-1] + size_of_maps[i][0])\n",
    "    n_encodings_234.append(n_encodings_234[-1] + size_of_maps[i][0])\n",
    "    for j in range(1, len(arch_diff[i])):\n",
    "        # add_size = min(size_of_maps[i][j]*(2+arch_diff[i][j]), size_of_maps[i][0]*arch_diff[i][j])\n",
    "        add_size = size_of_maps[i][j] * arch_diff[i][j]\n",
    "        n_encodings_1.append(n_encodings_1[-1] + add_size)\n",
    "        n_encodings_234.append(n_encodings_234[-1] + size_of_maps[i][0]*arch_diff[i][j])\n",
    "\n",
    "n_encodings_1 = n_encodings_1[1:]\n",
    "n_encodings_234 = n_encodings_234[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(np.log(n_encodings_1), np.log(results_1['best_val_errs']), 'r-o', markersize=10, linewidth=2.0)\n",
    "plt.plot(np.log(n_encodings_234), np.log(results_2['best_val_errs']), 'b-o', markersize=10, linewidth=2.0)\n",
    "plt.plot(np.log(n_encodings_234), np.log(errs_3), 'k-o', markersize=10, linewidth=2.0)\n",
    "plt.plot(np.log(n_encodings_234), np.log(errs_4), 'c-o', markersize=10, linewidth=2.0)\n",
    "plt.xlabel('log(size of encodings)', fontsize=20)\n",
    "plt.ylabel('log(validation error)', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
