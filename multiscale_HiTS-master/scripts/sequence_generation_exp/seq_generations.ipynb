{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence generations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### created by Yuying Liu, 06/10/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is a template for sequence generation with different neural network architectures, including our multiscale HiTS, LSTM, ESN and CW-RNN. We carefully choose the number of hidden units for each so that the amount of trainable parameters are close. The {model}\\_pred.npy files are generated and will be further fed to other scripts for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../src/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import ResNet as resnet\n",
    "import rnn\n",
    "import esn\n",
    "import cwrnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_fluid = '../../data/Fluid/'\n",
    "path_to_flower = '../../data/Flower/'\n",
    "path_to_Bach = '../../data/Bach/'\n",
    "path_to_KS = '../../data/KS/'\n",
    "\n",
    "path_to_model = '../../models/'\n",
    "path_to_result = '../../results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluid_data = np.load(os.path.join(path_to_fluid, 'data.npy'))\n",
    "flower_data = np.load(os.path.join(path_to_flower, 'data.npy'))\n",
    "Bach_data = np.load(os.path.join(path_to_Bach, 'data.npy'))\n",
    "ks_data = np.load(os.path.join(path_to_KS, 'data.npy'))\n",
    "\n",
    "print('fluid data: ', fluid_data.shape)\n",
    "print('flower data: ', flower_data.shape)\n",
    "print('Bach data: ', Bach_data.shape)\n",
    "print('KS data: ', ks_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjustable parameters\n",
    "\n",
    "normalize = True                   # if to normalize the features \n",
    "data = fluid_data.T                # choose the sequence you want to generate\n",
    "model_prefix = 'Fluid'             # 'Fluid', 'Flower', 'KS' or 'Bach'\n",
    "n_forward = 6                      # number of training steps\n",
    "archs = [[22, 256, 22], \n",
    "         [22, 164, 22], \n",
    "         [22, 16, 22], \n",
    "         [22, 4, 22]]              # multscale HiTS architecture, details can be found in table 4\n",
    "step_sizes = [1, 4, 16, 64]        # step sizes of HiTSs, details can be found in Appendix A.3\n",
    "lr = 1e-3                          # learning rate\n",
    "max_epoch = 10000                  # maximum number of epochs\n",
    "batch_size = 100                   # training batch size\n",
    "\n",
    "if normalize:\n",
    "    mean_values = data.mean(0)\n",
    "    ranges = data.ptp(0)\n",
    "    data = (data - mean_values)/ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coupled NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy parameter\n",
    "dt = 1  \n",
    "\n",
    "# training\n",
    "models = []\n",
    "n_steps = data.shape[0] - 1  # number of forward steps\n",
    "for (arch, step_size) in zip(archs, step_sizes):\n",
    "    m = int(np.ceil(n_steps/(step_size*n_forward)))\n",
    "    pdata = np.zeros((m, step_size*n_forward+1, data.shape[1]))\n",
    "    for i in range(m):\n",
    "        start_idx = i*step_size*n_forward\n",
    "        end_idx = start_idx + step_size*n_forward + 1\n",
    "        tmp = data[start_idx:end_idx, :]\n",
    "        pdata[i, :tmp.shape[0], :] = tmp\n",
    "    dataset = resnet.DataSet(pdata, pdata, data[np.newaxis, :], dt, step_size, n_forward)\n",
    "    print('MODEL: '+model_prefix+'_D{}'.format(step_size))\n",
    "    model = resnet.ResNet(arch=arch, dt=dt, step_size=step_size)\n",
    "    model.train_net(dataset, max_epoch=max_epoch, batch_size=batch_size, lr=lr,\n",
    "                    model_path=os.path.join(path_to_model, model_predix, model_prefix+'_D{}.pt'.format(step_size)))\n",
    "    models.append(model)\n",
    "\n",
    "print('# of params: ', sum([sum(p.numel() for p in model.parameters() if p.requires_grad) for model in models]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for step_size in step_sizes:\n",
    "    models.append(torch.load(os.path.join(path_to_model, model_predix, model_prefix+'_D{}.pt'.format(step_size))))\n",
    "\n",
    "y_preds = resnet.vectorized_multi_scale_forecast(dataset.test_x, n_steps=n_steps, models=models)\n",
    "y_preds = torch.cat([dataset.test_x.unsqueeze(0), y_preds], dim=1).squeeze().detach().numpy()\n",
    "if normalize:\n",
    "    y_preds = y_preds * ranges + mean_values\n",
    "np.save(os.path.join(path_to_result, model_prefix, model_prefix + '_couple_pred.npy', y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the hidden size so that # of parameters match \n",
    "model = rnn.LSTMWrapper(data.shape[-1], 740)\n",
    "print('# of params: ', sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "# training\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "epoch = 0\n",
    "best_loss = 1e+5\n",
    "while epoch < max_epoch:\n",
    "    epoch += 1\n",
    "    preds = model(torch.tensor(data[np.newaxis, :-1, :]).float())\n",
    "    loss = criterion(preds, torch.tensor(data[np.newaxis, 1:, :]).float())\n",
    "    if best_loss <= 1e-8:\n",
    "        print('--> model has reached an accuracy of 1e-8! Finished training!')\n",
    "        break\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 1000 == 0:\n",
    "        print('epoch {}, training loss {}'.format(epoch, loss.item()))\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            print('(--> new model saved @ epoch {})'.format(epoch))\n",
    "            torch.save(model, os.path.join(path_to_model, model_predix, model_prefix+'_lstm.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(os.path.join(path_to_model, model_predix, model_prefix+'_lstm.pt'))\n",
    "y_init = torch.tensor(data[np.newaxis, [0], :]).float()\n",
    "y_preds = model(y_init, t=data.shape[0]-1)\n",
    "y_preds = torch.cat([y_init, y_preds], dim=1).squeeze().detach().numpy()\n",
    "if normalize:\n",
    "    y_preds = y_preds * ranges + mean_values\n",
    "np.save(os.path.join(path_to_result, model_prefix, model_prefix + '_lstm_pred.npy', y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reservoir computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the hidden size so that # of parameters match \n",
    "model = esn.ESN(data.shape[1], 1600)\n",
    "y_pred = model(torch.tensor(data[:-1, :]).float())\n",
    "truth = torch.tensor(data[1:, :]).float()\n",
    "W_out = y_pred.pinverse() @ truth\n",
    "print('# of params: ', W_out.shape[0]*W_out.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = torch.zeros(data.shape)\n",
    "y_preds[0, :] = torch.tensor(data[0, :]).float()\n",
    "\n",
    "h_pred = model.f(model.W_in @torch.tensor(data[0, :]).float())\n",
    "y_pred = torch.matmul(h_pred, W_out)\n",
    "y_preds[1, :] = y_pred\n",
    "for t in range(2, data.shape[0]):\n",
    "    h_pred = model.f(model.W_in @ y_pred + model.W_hat @ h_pred)\n",
    "    y_pred = torch.matmul(h_pred, W_out)\n",
    "    y_preds[t, :] = y_pred\n",
    "    \n",
    "y_preds = y_preds.detach().numpy()\n",
    "if normalize:\n",
    "    y_preds = y_preds * ranges + mean_values\n",
    "np.save(os.path.join(path_to_result, model_prefix, model_prefix + '_reservoir_pred.npy', y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cw-rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the hidden size so that # of parameters match \n",
    "model = cwrnn.CwRNN(data.shape[-1], 1570, 5)\n",
    "print('# of params: ', sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "# training\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "epoch = 0\n",
    "best_loss = 1e+5\n",
    "while epoch < max_epoch:\n",
    "    epoch += 1\n",
    "    preds = model(torch.tensor(data[np.newaxis, :-1, :]).float())\n",
    "    loss = criterion(preds, torch.tensor(data[np.newaxis, 1:, :]).float())\n",
    "    if best_loss <= 1e-8:\n",
    "        print('--> model has reached an accuracy of 1e-8! Finished training!')\n",
    "        break\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 1000 == 0:\n",
    "        print('epoch {}, training loss {}'.format(epoch, loss.item()))\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            print('(--> new model saved @ epoch {})'.format(epoch))\n",
    "            torch.save(model, os.path.join(path_to_model, model_predix, model_prefix+'_cwrnn.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(os.path.join(path_to_model, model_predix, model_prefix+'_cwrnn.pt'))\n",
    "y_preds = model.forecast(torch.tensor(data[[0], :]).float(), data.shape[0]-1)\n",
    "y_preds = torch.cat([torch.tensor(data[[0], :]).float(), y_preds.squeeze()], dim=0).detach().numpy()\n",
    "if normalize:\n",
    "    y_preds = y_preds * ranges + mean_values\n",
    "np.save(os.path.join(path_to_result, model_prefix, model_prefix + '_cwrnn_pred.npy', y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
