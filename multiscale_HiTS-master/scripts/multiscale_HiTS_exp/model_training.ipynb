{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ResNets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### created by Yuying Liu, 04/30/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is a template for training neural network time-steppers for different systems and different time scales. To reproduce the results in the paper, one needs to obtain all 11 neural network models for each nonlinear system under study. For setup details, please refer to Table 2 in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../src/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import ResNet as net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjustables\n",
    "\n",
    "k = 10                        # model index: should be in {0, 2, ..., 10}\n",
    "dt = 0.01                     # time unit: 0.0005 for Lorenz and 0.01 for others\n",
    "system = 'Hyperbolic'         # system name: 'Hyperbolic', 'Cubic', 'VanDerPol', 'Hopf' or 'Lorenz'\n",
    "noise = 0.0                   # noise percentage: 0.00, 0.01 or 0.02\n",
    "\n",
    "lr = 1e-3                     # learning rate\n",
    "max_epoch = 100000            # the maximum training epoch \n",
    "batch_size = 320              # training batch size\n",
    "arch = [2, 128, 128, 128, 2]  # architecture of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "data_dir = os.path.join('data/', system)\n",
    "model_dir = os.path.join('models/', system)\n",
    "\n",
    "# global const\n",
    "n_forward = 5\n",
    "ks = list(range(11))\n",
    "step_size = [2**k for k in ks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "och 88000, training loss 1.4571909332516952e-06, validation loss 1.6209128261834849e-06\n",
      "epoch 89000, training loss 7.047125905046414e-07, validation loss 7.684934075768979e-07\n",
      "epoch 90000, training loss 1.0850900480363634e-06, validation loss 1.2295838587306207e-06\n",
      "epoch 91000, training loss 2.1727601051679812e-06, validation loss 2.4885491711756913e-06\n",
      "epoch 92000, training loss 4.7641373157603084e-07, validation loss 5.60725652576366e-07\n",
      "epoch 93000, training loss 1.58363576474585e-07, validation loss 2.5484729349045665e-07\n",
      "epoch 94000, training loss 2.2047673553515779e-07, validation loss 3.0431380082518444e-07\n",
      "epoch 95000, training loss 5.502676714286281e-08, validation loss 1.3334079085325357e-07\n",
      "epoch 96000, training loss 8.309528709560254e-08, validation loss 1.5882213233453513e-07\n",
      "epoch 97000, training loss 8.748875046649118e-08, validation loss 1.617100764406132e-07\n",
      "epoch 98000, training loss 7.324416628762265e-07, validation loss 8.888897582437494e-07\n",
      "epoch 99000, training loss 3.5318072377776843e-07, validation loss 4.4014691980009957e-07\n",
      "epoch 100000, training loss 1.034465739735424e-07, validation loss 1.7698337728688784e-07\n",
      "create model model_D512_noise0.0.pt ...\n",
      "epoch 1000, training loss 8.548860932933167e-05, validation loss 8.430373418377712e-05\n",
      "(--> new model saved @ epoch 1000)\n",
      "epoch 2000, training loss 1.6675558072165586e-05, validation loss 1.8094304323312826e-05\n",
      "(--> new model saved @ epoch 2000)\n",
      "epoch 3000, training loss 4.420817731443094e-06, validation loss 4.54632890978246e-06\n",
      "(--> new model saved @ epoch 3000)\n",
      "epoch 4000, training loss 1.9959177279815776e-06, validation loss 2.4085434233711567e-06\n",
      "(--> new model saved @ epoch 4000)\n",
      "epoch 5000, training loss 2.4072594442259287e-06, validation loss 2.6344850994064473e-06\n",
      "epoch 6000, training loss 2.049152953986777e-06, validation loss 2.219422640337143e-06\n",
      "(--> new model saved @ epoch 6000)\n",
      "epoch 7000, training loss 7.267424280144041e-06, validation loss 7.5800307968165725e-06\n",
      "epoch 8000, training loss 7.821041435818188e-06, validation loss 8.229656486946624e-06\n",
      "epoch 9000, training loss 5.771688847744372e-06, validation loss 6.187162853166228e-06\n",
      "epoch 10000, training loss 1.698740447864111e-06, validation loss 1.7123251154771424e-06\n",
      "(--> new model saved @ epoch 10000)\n",
      "epoch 11000, training loss 5.797536459795083e-07, validation loss 7.280938802978199e-07\n",
      "(--> new model saved @ epoch 11000)\n",
      "epoch 12000, training loss 1.1293831221337314e-06, validation loss 1.3224751000961987e-06\n",
      "epoch 13000, training loss 6.085529662414046e-07, validation loss 7.314827144000446e-07\n",
      "epoch 14000, training loss 3.0894495921529597e-06, validation loss 3.2571579140494578e-06\n",
      "epoch 15000, training loss 5.927642519054643e-07, validation loss 7.106470434337098e-07\n",
      "(--> new model saved @ epoch 15000)\n",
      "epoch 16000, training loss 5.321141543390695e-06, validation loss 5.738878826377913e-06\n",
      "epoch 17000, training loss 6.18650460637582e-07, validation loss 7.514624940085923e-07\n",
      "epoch 18000, training loss 1.69042948527931e-06, validation loss 1.6323252793881693e-06\n",
      "epoch 19000, training loss 9.357998351333663e-06, validation loss 9.28794815990841e-06\n",
      "epoch 20000, training loss 3.304419067262643e-07, validation loss 4.038329848299327e-07\n",
      "(--> new model saved @ epoch 20000)\n",
      "epoch 21000, training loss 4.924646873405436e-06, validation loss 4.937779067404335e-06\n",
      "epoch 22000, training loss 2.1064943211968057e-07, validation loss 3.0131505468489195e-07\n",
      "(--> new model saved @ epoch 22000)\n",
      "epoch 23000, training loss 1.8497965470487543e-07, validation loss 2.664064595592208e-07\n",
      "(--> new model saved @ epoch 23000)\n",
      "epoch 24000, training loss 2.1398038541065034e-07, validation loss 3.104104564499721e-07\n",
      "epoch 25000, training loss 9.255452368961414e-07, validation loss 1.0056786550194374e-06\n",
      "epoch 26000, training loss 3.3017672649293672e-06, validation loss 3.236540351281292e-06\n",
      "epoch 27000, training loss 4.4864236770081334e-07, validation loss 5.237351956566272e-07\n",
      "epoch 28000, training loss 2.3598262544055615e-07, validation loss 3.2857002452146844e-07\n",
      "epoch 29000, training loss 9.09949733340909e-07, validation loss 9.806528851186158e-07\n",
      "epoch 30000, training loss 5.7723905229067896e-06, validation loss 5.839334789925488e-06\n",
      "epoch 31000, training loss 9.801480700843967e-06, validation loss 1.0158213626709767e-05\n",
      "epoch 32000, training loss 1.8614525743032573e-06, validation loss 1.8480380958862952e-06\n",
      "epoch 33000, training loss 1.9374800785953994e-07, validation loss 2.849253348813363e-07\n",
      "epoch 34000, training loss 8.25837048523681e-07, validation loss 1.0097567155753495e-06\n",
      "epoch 35000, training loss 3.765711426240159e-06, validation loss 3.588134632082074e-06\n",
      "epoch 36000, training loss 1.632988642086275e-06, validation loss 1.9091678495897213e-06\n",
      "epoch 37000, training loss 1.2380126008793013e-06, validation loss 1.2280241890039179e-06\n",
      "epoch 38000, training loss 3.7622416471094766e-07, validation loss 5.151383106749563e-07\n",
      "epoch 39000, training loss 1.1819589929018548e-07, validation loss 2.169969519627557e-07\n",
      "(--> new model saved @ epoch 39000)\n",
      "epoch 40000, training loss 1.1747641792680952e-06, validation loss 1.177749140879314e-06\n",
      "epoch 41000, training loss 6.031814905327337e-07, validation loss 7.790591780576506e-07\n",
      "epoch 42000, training loss 6.552789386660152e-07, validation loss 6.806129704273189e-07\n",
      "epoch 43000, training loss 1.538674951007124e-06, validation loss 1.6913376157390303e-06\n",
      "epoch 44000, training loss 1.443509063392412e-07, validation loss 2.695736327495979e-07\n",
      "epoch 45000, training loss 3.896132056979695e-06, validation loss 4.138664280617377e-06\n",
      "epoch 46000, training loss 4.947290221934963e-07, validation loss 5.985855295875808e-07\n",
      "epoch 47000, training loss 3.218565325369127e-07, validation loss 4.013509169453755e-07\n",
      "epoch 48000, training loss 7.456616799572657e-07, validation loss 8.953587098403659e-07\n",
      "epoch 49000, training loss 1.3217706964496756e-06, validation loss 1.368076482322067e-06\n",
      "epoch 50000, training loss 1.305082037106331e-06, validation loss 1.3644332739204401e-06\n",
      "epoch 51000, training loss 2.8340213020783267e-07, validation loss 4.4061138737561123e-07\n",
      "epoch 52000, training loss 8.076810331658635e-07, validation loss 8.944816158873437e-07\n",
      "epoch 53000, training loss 1.2077090332240914e-06, validation loss 1.3719517255594837e-06\n",
      "epoch 54000, training loss 4.315782859976025e-07, validation loss 4.7060535734999576e-07\n",
      "epoch 55000, training loss 2.3420699335474637e-07, validation loss 3.2259205795526213e-07\n",
      "epoch 56000, training loss 1.9795389505361527e-07, validation loss 3.290498966634914e-07\n",
      "epoch 57000, training loss 4.159675881965086e-06, validation loss 4.290132892492693e-06\n",
      "epoch 58000, training loss 7.534822543675546e-08, validation loss 1.7036748545251612e-07\n",
      "(--> new model saved @ epoch 58000)\n",
      "epoch 59000, training loss 1.233491957464139e-07, validation loss 2.187156837862858e-07\n",
      "epoch 60000, training loss 8.682579277774494e-07, validation loss 9.699577958599548e-07\n",
      "epoch 61000, training loss 3.2559202622906014e-07, validation loss 4.1348775425831263e-07\n",
      "epoch 62000, training loss 1.331386130232204e-07, validation loss 2.2802828425483312e-07\n",
      "epoch 63000, training loss 4.464187952635257e-07, validation loss 5.773746920567646e-07\n",
      "epoch 64000, training loss 1.4456230701398454e-07, validation loss 2.1096772684359166e-07\n",
      "epoch 65000, training loss 8.678568974573864e-08, validation loss 1.666853819415337e-07\n",
      "(--> new model saved @ epoch 65000)\n",
      "epoch 66000, training loss 1.155694562271492e-07, validation loss 1.8794717959735863e-07\n",
      "epoch 67000, training loss 2.947177222267783e-07, validation loss 3.690187497795705e-07\n",
      "epoch 68000, training loss 8.957983936852543e-07, validation loss 9.275061643165827e-07\n",
      "epoch 69000, training loss 5.2975003939081944e-08, validation loss 1.4567308426194359e-07\n",
      "(--> new model saved @ epoch 69000)\n",
      "epoch 70000, training loss 6.598196478080354e-07, validation loss 7.354466333708842e-07\n",
      "epoch 71000, training loss 2.1383594628332503e-07, validation loss 3.5394435826674453e-07\n",
      "epoch 72000, training loss 4.8922530027084576e-08, validation loss 1.431984060218383e-07\n",
      "(--> new model saved @ epoch 72000)\n",
      "epoch 73000, training loss 1.4546868953857484e-07, validation loss 2.432752523873205e-07\n",
      "epoch 74000, training loss 6.042683367013524e-07, validation loss 6.915296353326994e-07\n",
      "epoch 75000, training loss 8.489634524266876e-07, validation loss 9.322550340584712e-07\n",
      "epoch 76000, training loss 6.319783096842002e-07, validation loss 6.957310461075394e-07\n",
      "epoch 77000, training loss 6.13756512279906e-08, validation loss 1.698357579016374e-07\n",
      "epoch 78000, training loss 4.404198250540503e-07, validation loss 5.214494649408152e-07\n",
      "epoch 79000, training loss 1.0199830313695202e-07, validation loss 1.8653931022072356e-07\n",
      "epoch 80000, training loss 6.612083325308049e-08, validation loss 1.5068818015606666e-07\n",
      "epoch 81000, training loss 1.4359933402374736e-06, validation loss 1.5314092252083356e-06\n",
      "epoch 82000, training loss 1.8129954071355314e-07, validation loss 2.9728417416663433e-07\n",
      "epoch 83000, training loss 4.1432525677009835e-07, validation loss 5.401620910561178e-07\n",
      "epoch 84000, training loss 1.0029366848129939e-07, validation loss 2.0776965925506374e-07\n",
      "epoch 85000, training loss 8.317523736423027e-08, validation loss 1.5588805979405151e-07\n",
      "epoch 86000, training loss 2.669633261120907e-07, validation loss 3.3648939279373735e-07\n",
      "epoch 87000, training loss 1.1032875590899494e-07, validation loss 1.9902027759144403e-07\n",
      "epoch 88000, training loss 1.401049644300656e-06, validation loss 1.6260829625025508e-06\n",
      "epoch 89000, training loss 6.630254574702121e-06, validation loss 6.841665253887186e-06\n",
      "epoch 90000, training loss 1.1137425417473423e-06, validation loss 1.1822467058664188e-06\n",
      "epoch 91000, training loss 4.392342816572636e-06, validation loss 4.684920440922724e-06\n",
      "epoch 92000, training loss 3.284827698735171e-07, validation loss 4.3796049453703745e-07\n",
      "epoch 93000, training loss 7.478403176719439e-07, validation loss 7.885666946094716e-07\n",
      "epoch 94000, training loss 6.392981788394536e-08, validation loss 1.5145855059017777e-07\n",
      "epoch 95000, training loss 2.450740055337519e-07, validation loss 2.838041268660163e-07\n",
      "epoch 96000, training loss 2.1364169242588105e-06, validation loss 2.1012854176660767e-06\n",
      "epoch 97000, training loss 9.179248081636615e-07, validation loss 1.0686134146453696e-06\n",
      "epoch 98000, training loss 5.697608571608725e-07, validation loss 6.276294470808352e-07\n",
      "epoch 99000, training loss 1.7468359203576256e-07, validation loss 2.657669426753273e-07\n",
      "epoch 100000, training loss 1.1229547425273267e-07, validation loss 1.7764165249900543e-07\n",
      "create model model_D1024_noise0.0.pt ...\n",
      "epoch 1000, training loss 1.4775635008845711e-06, validation loss 2.0530915207928047e-06\n",
      "(--> new model saved @ epoch 1000)\n",
      "epoch 2000, training loss 5.273433544061845e-06, validation loss 5.799309292342514e-06\n",
      "epoch 3000, training loss 7.263982752192533e-06, validation loss 7.287329026439693e-06\n",
      "epoch 4000, training loss 7.307091323127679e-07, validation loss 8.81181733802805e-07\n",
      "(--> new model saved @ epoch 4000)\n",
      "epoch 5000, training loss 1.1449753856140887e-06, validation loss 1.297972062275221e-06\n",
      "epoch 6000, training loss 3.126047522528097e-05, validation loss 3.102716073044576e-05\n",
      "epoch 7000, training loss 4.229747901263181e-06, validation loss 4.268520115147112e-06\n",
      "epoch 8000, training loss 7.249320219671063e-07, validation loss 7.790388281136984e-07\n",
      "(--> new model saved @ epoch 8000)\n",
      "epoch 9000, training loss 4.885811449639732e-06, validation loss 5.115381100040395e-06\n",
      "epoch 10000, training loss 2.940145691354701e-07, validation loss 3.9262627637981495e-07\n",
      "(--> new model saved @ epoch 10000)\n",
      "epoch 11000, training loss 1.4091037883190438e-06, validation loss 1.421266574652691e-06\n",
      "epoch 12000, training loss 6.475974032582599e-07, validation loss 7.297805950656766e-07\n",
      "epoch 13000, training loss 2.5939996817214706e-07, validation loss 3.4480379440537945e-07\n",
      "(--> new model saved @ epoch 13000)\n",
      "epoch 14000, training loss 3.225955538255221e-07, validation loss 4.169381497831637e-07\n",
      "epoch 15000, training loss 2.7262658477411605e-06, validation loss 2.7527898964763153e-06\n",
      "epoch 16000, training loss 7.803503763170738e-07, validation loss 8.047392157095601e-07\n",
      "epoch 17000, training loss 2.150651198462583e-06, validation loss 2.1342254967748886e-06\n",
      "epoch 18000, training loss 2.698043317650445e-07, validation loss 3.54500798493973e-07\n",
      "epoch 19000, training loss 2.161519745413898e-07, validation loss 3.0541605156031437e-07\n",
      "(--> new model saved @ epoch 19000)\n",
      "epoch 20000, training loss 1.31816733528467e-07, validation loss 1.9915772497824946e-07\n",
      "(--> new model saved @ epoch 20000)\n",
      "epoch 21000, training loss 1.7286442925978918e-06, validation loss 1.8084875819113222e-06\n",
      "epoch 22000, training loss 3.426805960771162e-06, validation loss 3.453289991739439e-06\n",
      "epoch 23000, training loss 2.775177847524901e-07, validation loss 3.357114053414989e-07\n",
      "epoch 24000, training loss 5.424613505056186e-07, validation loss 5.733876378144487e-07\n",
      "epoch 25000, training loss 7.055846822368039e-07, validation loss 8.406814231420867e-07\n",
      "epoch 26000, training loss 6.320258876257867e-07, validation loss 6.943722610230907e-07\n",
      "epoch 27000, training loss 1.2021877182633034e-06, validation loss 1.2888347100670217e-06\n",
      "epoch 28000, training loss 5.362845172385278e-07, validation loss 6.115079713708838e-07\n",
      "epoch 29000, training loss 1.698536721050914e-06, validation loss 1.8084393786921282e-06\n",
      "epoch 30000, training loss 2.531865561650193e-07, validation loss 3.2862874377315165e-07\n",
      "epoch 31000, training loss 1.949567149495124e-06, validation loss 2.023657316385652e-06\n",
      "epoch 32000, training loss 2.2187161619058315e-07, validation loss 2.812943478147645e-07\n",
      "epoch 33000, training loss 2.0680110992543632e-06, validation loss 2.1633463802572805e-06\n",
      "epoch 34000, training loss 7.625705222835677e-08, validation loss 1.3969786039069731e-07\n",
      "(--> new model saved @ epoch 34000)\n",
      "epoch 35000, training loss 7.23653101886157e-08, validation loss 1.3127012721270148e-07\n",
      "(--> new model saved @ epoch 35000)\n",
      "epoch 36000, training loss 7.942609272504342e-07, validation loss 8.018870403248002e-07\n",
      "epoch 37000, training loss 3.77350147573452e-07, validation loss 4.397178656745382e-07\n",
      "epoch 38000, training loss 6.628722530876985e-07, validation loss 7.211218644442852e-07\n",
      "epoch 39000, training loss 2.5261433620471507e-06, validation loss 2.554914544816711e-06\n",
      "epoch 40000, training loss 7.318382131416001e-07, validation loss 7.94381492141838e-07\n",
      "epoch 41000, training loss 2.888099857045745e-07, validation loss 3.417423783957929e-07\n",
      "epoch 42000, training loss 1.7293524479100597e-06, validation loss 1.7560395235705073e-06\n",
      "epoch 43000, training loss 2.006738100135408e-07, validation loss 2.692703731099755e-07\n",
      "epoch 44000, training loss 2.123298656897532e-07, validation loss 2.659080848843587e-07\n",
      "epoch 45000, training loss 5.891299110771797e-07, validation loss 6.472570248661214e-07\n",
      "epoch 46000, training loss 1.3767238726813957e-07, validation loss 2.0151877322405198e-07\n",
      "epoch 47000, training loss 1.4600736903958023e-06, validation loss 1.5062474858495989e-06\n",
      "epoch 48000, training loss 8.561047479815898e-07, validation loss 8.963017421592667e-07\n",
      "epoch 49000, training loss 3.054302624150296e-07, validation loss 3.5418602806203126e-07\n",
      "epoch 50000, training loss 5.214935185904324e-07, validation loss 5.800243911835423e-07\n",
      "epoch 51000, training loss 1.5699915820732713e-05, validation loss 1.531721318315249e-05\n",
      "epoch 52000, training loss 1.343566680134245e-07, validation loss 1.9308198773160257e-07\n",
      "epoch 53000, training loss 1.2724008513487206e-07, validation loss 1.78948752704855e-07\n",
      "epoch 54000, training loss 9.753896392794559e-07, validation loss 9.679093864178867e-07\n",
      "epoch 55000, training loss 1.7599522550426627e-07, validation loss 2.2998082727099245e-07\n",
      "epoch 56000, training loss 4.4495328666016576e-07, validation loss 4.740639951705816e-07\n",
      "epoch 57000, training loss 4.0869682038646715e-07, validation loss 4.62198926243218e-07\n",
      "epoch 58000, training loss 7.28599388821749e-07, validation loss 7.861329436309461e-07\n",
      "epoch 59000, training loss 6.360507995850639e-07, validation loss 6.684225581921055e-07\n",
      "epoch 60000, training loss 6.251831763393056e-08, validation loss 1.1437098379474264e-07\n",
      "(--> new model saved @ epoch 60000)\n",
      "epoch 61000, training loss 6.575209710035779e-08, validation loss 1.2786387060259585e-07\n",
      "epoch 62000, training loss 2.5625200805734494e-07, validation loss 2.816136088767962e-07\n",
      "epoch 63000, training loss 3.435310134136671e-07, validation loss 3.756178728053783e-07\n",
      "epoch 64000, training loss 2.2072303806908167e-07, validation loss 2.6589214030536823e-07\n",
      "epoch 65000, training loss 1.3835787626703677e-07, validation loss 1.8612554697483574e-07\n",
      "epoch 66000, training loss 1.1473491667857161e-07, validation loss 1.6719302209367015e-07\n",
      "epoch 67000, training loss 3.6924745927535696e-08, validation loss 8.771232984372546e-08\n",
      "(--> new model saved @ epoch 67000)\n",
      "epoch 68000, training loss 3.8901116994338736e-08, validation loss 9.022678426617858e-08\n",
      "epoch 69000, training loss 1.0452311016706517e-07, validation loss 1.6483679132761608e-07\n",
      "epoch 70000, training loss 2.972504489662242e-06, validation loss 2.9545983579737367e-06\n",
      "epoch 71000, training loss 1.5164823707891628e-07, validation loss 2.1111310388732818e-07\n",
      "epoch 72000, training loss 4.424340147579642e-07, validation loss 4.889824936071818e-07\n",
      "epoch 73000, training loss 6.730344921379583e-07, validation loss 6.950601232347253e-07\n",
      "epoch 74000, training loss 2.9152590741432505e-07, validation loss 3.6856084761893726e-07\n",
      "epoch 75000, training loss 1.0468009037367665e-07, validation loss 1.647189407094629e-07\n",
      "epoch 76000, training loss 4.431102951230059e-08, validation loss 9.830819180933759e-08\n",
      "epoch 77000, training loss 3.804477444191434e-07, validation loss 4.3273777805552527e-07\n",
      "epoch 78000, training loss 4.6027085431887826e-07, validation loss 4.938093525197473e-07\n",
      "epoch 79000, training loss 1.2575777930123877e-07, validation loss 1.7840233113020076e-07\n",
      "epoch 80000, training loss 1.496288035696125e-07, validation loss 2.0368980813145754e-07\n",
      "epoch 81000, training loss 4.851804646932578e-07, validation loss 5.479453193402151e-07\n",
      "epoch 82000, training loss 3.508290319587104e-06, validation loss 3.4280958516319515e-06\n",
      "epoch 83000, training loss 6.586437280020618e-07, validation loss 7.608691134919354e-07\n",
      "epoch 84000, training loss 7.122736889186854e-08, validation loss 1.1729725457598761e-07\n",
      "epoch 85000, training loss 1.1705759561664308e-07, validation loss 1.721911786489727e-07\n",
      "epoch 86000, training loss 5.510868916758227e-08, validation loss 1.0155238783227105e-07\n",
      "epoch 87000, training loss 7.976717029123392e-07, validation loss 8.363946903955366e-07\n",
      "epoch 88000, training loss 1.0371328471592278e-06, validation loss 1.1107981663371902e-06\n",
      "epoch 89000, training loss 9.236013056579395e-07, validation loss 9.275006505049532e-07\n",
      "epoch 90000, training loss 3.83004490345229e-08, validation loss 9.596973171710488e-08\n",
      "epoch 91000, training loss 2.1915346223977394e-05, validation loss 2.199367736466229e-05\n",
      "epoch 92000, training loss 4.819328935923295e-08, validation loss 1.0165842923015589e-07\n",
      "epoch 93000, training loss 5.6176972407229187e-08, validation loss 1.0868648558925997e-07\n",
      "epoch 94000, training loss 7.037417049104988e-08, validation loss 1.207710056405631e-07\n",
      "epoch 95000, training loss 1.1042609315836671e-07, validation loss 1.5148731336012133e-07\n",
      "epoch 96000, training loss 3.2523082893476385e-08, validation loss 8.70678746878184e-08\n",
      "(--> new model saved @ epoch 96000)\n",
      "epoch 97000, training loss 5.115532886179608e-08, validation loss 1.0472246714243738e-07\n",
      "epoch 98000, training loss 7.872374681028305e-07, validation loss 8.288425306091085e-07\n",
      "epoch 99000, training loss 8.105640603162101e-08, validation loss 1.4205529907940218e-07\n",
      "epoch 100000, training loss 2.326554238152312e-08, validation loss 7.605844842828446e-08\n",
      "(--> new model saved @ epoch 100000)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "for step in step_size:\n",
    "    train_data = np.load(os.path.join(data_dir, 'train_noise{}.npy'.format(noise)))\n",
    "    val_data = np.load(os.path.join(data_dir, 'val_noise{}.npy'.format(noise)))\n",
    "    test_data = np.load(os.path.join(data_dir, 'test_noise{}.npy'.format(noise)))\n",
    "    n_train = train_data.shape[0]\n",
    "    n_val = val_data.shape[0]\n",
    "    n_test = test_data.shape[0]\n",
    "\n",
    "    # create dataset object\n",
    "    dataset = net.DataSet(train_data, val_data, test_data, dt, step, n_forward)\n",
    "    model_name = 'model_D{}_noise{}.pt'.format(step, noise)\n",
    "\n",
    "    # create/load model object\n",
    "    try:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        model = torch.load(os.path.join(model_dir, model_name), map_location=device)\n",
    "        model.device = device\n",
    "    except:\n",
    "        print('create model {} ...'.format(model_name))\n",
    "        model = net.ResNet(arch=arch, dt=dt, step_size=step)\n",
    "\n",
    "    # training\n",
    "    model.train_net(dataset, max_epoch=max_epoch, batch_size=batch_size, lr=lr,\n",
    "                    model_path=os.path.join(model_dir, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "create model model_D1_noise0.0.pt ...\n",
      "epoch 1000, training loss 4.034102971672837e-07, validation loss 5.656399935105583e-07\n",
      "(--> new model saved @ epoch 1000)\n",
      "epoch 2000, training loss 2.451866407682246e-07, validation loss 3.0321589861159737e-07\n",
      "(--> new model saved @ epoch 2000)\n",
      "epoch 3000, training loss 4.7545958636874275e-07, validation loss 5.787879899799009e-07\n",
      "epoch 4000, training loss 4.7593735530426784e-07, validation loss 5.614136284748383e-07\n",
      "epoch 5000, training loss 2.749507075350266e-07, validation loss 2.979831208449468e-07\n",
      "(--> new model saved @ epoch 5000)\n",
      "epoch 6000, training loss 8.04062452175458e-08, validation loss 1.0738859401726586e-07\n",
      "(--> new model saved @ epoch 6000)\n",
      "epoch 7000, training loss 1.4594854746974306e-06, validation loss 1.446823830519861e-06\n",
      "epoch 8000, training loss 6.284055302785418e-07, validation loss 6.253319497773191e-07\n",
      "epoch 9000, training loss 2.5177821498800768e-06, validation loss 2.5279121018684236e-06\n",
      "epoch 10000, training loss 9.716604836285114e-07, validation loss 1.0141965276488918e-06\n",
      "epoch 11000, training loss 5.011990538150712e-07, validation loss 5.266618359200947e-07\n",
      "epoch 12000, training loss 3.317127834634448e-07, validation loss 3.4030009032903763e-07\n",
      "epoch 13000, training loss 6.517864648003524e-08, validation loss 7.000425483738582e-08\n",
      "(--> new model saved @ epoch 13000)\n",
      "epoch 14000, training loss 4.7065236685739364e-07, validation loss 4.788984142578556e-07\n",
      "epoch 15000, training loss 4.222680445309379e-07, validation loss 4.041951626732043e-07\n",
      "epoch 16000, training loss 4.629863781246968e-08, validation loss 4.96571672670143e-08\n",
      "(--> new model saved @ epoch 16000)\n",
      "epoch 17000, training loss 2.2284394773919303e-08, validation loss 2.601776394328681e-08\n",
      "(--> new model saved @ epoch 17000)\n",
      "epoch 18000, training loss 3.354560718094035e-08, validation loss 3.7619326320736945e-08\n",
      "epoch 19000, training loss 2.934185658887145e-07, validation loss 2.935229872491618e-07\n",
      "epoch 20000, training loss 8.679176488612939e-08, validation loss 8.731959866281613e-08\n",
      "epoch 21000, training loss 3.976584039833142e-08, validation loss 4.168673584103999e-08\n",
      "epoch 22000, training loss 2.7576442107601906e-07, validation loss 2.8492229375842726e-07\n",
      "epoch 23000, training loss 5.766496258274856e-08, validation loss 5.9575203437134405e-08\n",
      "epoch 24000, training loss 2.036676072236787e-08, validation loss 2.182774494485784e-08\n",
      "(--> new model saved @ epoch 24000)\n",
      "epoch 25000, training loss 5.661682234148202e-09, validation loss 7.996020734424292e-09\n",
      "(--> new model saved @ epoch 25000)\n",
      "--> model has reached an accuracy of 1e-8! Finished training!\n",
      "--> new model saved @ epoch 25001\n"
     ]
    }
   ],
   "source": [
    "# model_name = 'model_D{}_noise{}.pt'.format(step_size, noise)\n",
    "\n",
    "# # create/load model object\n",
    "# try:\n",
    "#     device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#     model = torch.load(os.path.join(model_dir, model_name), map_location=device)\n",
    "#     model.device = device\n",
    "# except:\n",
    "#     print('create model {} ...'.format(model_name))\n",
    "#     model = net.ResNet(arch=arch, dt=dt, step_size=step_size)\n",
    "\n",
    "# # training\n",
    "# model.train_net(dataset, max_epoch=max_epoch, batch_size=batch_size, lr=lr,\n",
    "#                 model_path=os.path.join(model_dir, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3710jvsc74a57bd00d235557d0feb0efea5d5740b2690d48a2120004fe3a587911c97a32194e2c15",
   "display_name": "Python 3.7.10 64-bit ('temp': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}