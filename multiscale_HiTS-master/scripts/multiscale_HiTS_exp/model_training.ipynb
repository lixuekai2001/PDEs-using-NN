{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ResNets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### created by Yuying Liu, 04/30/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is a template for training neural network time-steppers for different systems and different time scales. To reproduce the results in the paper, one needs to obtain all 11 neural network models for each nonlinear system under study. For setup details, please refer to Table 2 in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../src/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import ResNet as net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjustables\n",
    "\n",
    "k = 10                        # model index: should be in {0, 2, ..., 10}\n",
    "dt = 0.01                     # time unit: 0.0005 for Lorenz and 0.01 for others\n",
    "system = 'Hyperbolic'         # system name: 'Hyperbolic', 'Cubic', 'VanDerPol', 'Hopf' or 'Lorenz'\n",
    "noise = 0.0                   # noise percentage: 0.00, 0.01 or 0.02\n",
    "\n",
    "lr = 1e-3                     # learning rate\n",
    "max_epoch = 500000            # the maximum training epoch \n",
    "batch_size = 320              # training batch size\n",
    "arch = [2, 128, 128, 128, 2]  # architecture of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "data_dir = os.path.join('data/', system)\n",
    "model_dir = os.path.join('models/', system)\n",
    "\n",
    "# global const\n",
    "n_forward = 5\n",
    "step_size = 2**k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data = np.load(os.path.join(data_dir, 'train_noise{}.npy'.format(noise)))\n",
    "val_data = np.load(os.path.join(data_dir, 'val_noise{}.npy'.format(noise)))\n",
    "test_data = np.load(os.path.join(data_dir, 'test_noise{}.npy'.format(noise)))\n",
    "n_train = train_data.shape[0]\n",
    "n_val = val_data.shape[0]\n",
    "n_test = test_data.shape[0]\n",
    "\n",
    "# create dataset object\n",
    "dataset = net.DataSet(train_data, val_data, test_data, dt, step_size, n_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "579981055e-08\n",
      "epoch 281000, training loss 1.7632535787015513e-07, validation loss 2.2838884206066723e-07\n",
      "epoch 282000, training loss 3.3617300942978545e-08, validation loss 7.235792054416379e-08\n",
      "epoch 283000, training loss 3.3195138371411304e-07, validation loss 3.9795136785869545e-07\n",
      "epoch 284000, training loss 6.111683319431904e-07, validation loss 6.811233106418513e-07\n",
      "epoch 285000, training loss 3.559140537845451e-08, validation loss 7.312746674870141e-08\n",
      "epoch 286000, training loss 1.4560803229812791e-08, validation loss 5.817731718593677e-08\n",
      "epoch 287000, training loss 6.714669353868885e-08, validation loss 1.205312400998082e-07\n",
      "epoch 288000, training loss 1.1454019244183655e-07, validation loss 1.5219545446143457e-07\n",
      "epoch 289000, training loss 2.58922995044486e-07, validation loss 3.0776507742302783e-07\n",
      "epoch 290000, training loss 3.6762056510042385e-08, validation loss 7.669358126349834e-08\n",
      "epoch 291000, training loss 2.7060215401775167e-08, validation loss 6.715009703839314e-08\n",
      "epoch 292000, training loss 3.6879374221143735e-08, validation loss 8.524789052444248e-08\n",
      "epoch 293000, training loss 1.0726889598799971e-07, validation loss 1.464112244775606e-07\n",
      "epoch 294000, training loss 3.012520366496574e-08, validation loss 7.124631906663126e-08\n",
      "epoch 295000, training loss 4.1790036675593e-07, validation loss 5.117429964229814e-07\n",
      "epoch 296000, training loss 4.6195395952963736e-07, validation loss 5.607315074485086e-07\n",
      "epoch 297000, training loss 4.7819010973171316e-08, validation loss 8.305424614718504e-08\n",
      "epoch 298000, training loss 3.8566998483702264e-08, validation loss 7.585990147163102e-08\n",
      "epoch 299000, training loss 5.029723126881436e-08, validation loss 9.543128243194587e-08\n",
      "epoch 300000, training loss 1.2509056546150532e-07, validation loss 1.9050986566071515e-07\n",
      "epoch 301000, training loss 5.646864309483135e-08, validation loss 9.09725841324871e-08\n",
      "epoch 302000, training loss 2.7374514388611715e-07, validation loss 3.6194271046952053e-07\n",
      "epoch 303000, training loss 2.860517440694821e-07, validation loss 3.4684137517615454e-07\n",
      "epoch 304000, training loss 3.510012902552262e-08, validation loss 7.393617096340677e-08\n",
      "epoch 305000, training loss 8.109419695756515e-07, validation loss 8.490967502439162e-07\n",
      "epoch 306000, training loss 7.485874675694504e-07, validation loss 7.873083518461499e-07\n",
      "epoch 307000, training loss 1.7137497820840508e-07, validation loss 2.1914300418757193e-07\n",
      "epoch 308000, training loss 1.607474331422054e-07, validation loss 1.996926499714391e-07\n",
      "epoch 309000, training loss 1.4666858305645292e-07, validation loss 1.8724070116604707e-07\n",
      "epoch 310000, training loss 3.9136128293648653e-07, validation loss 4.0480298935108294e-07\n",
      "epoch 311000, training loss 3.4196713727396855e-07, validation loss 3.952738723000948e-07\n",
      "epoch 312000, training loss 2.3081213385012234e-08, validation loss 6.583206868526759e-08\n",
      "epoch 313000, training loss 4.168536804627365e-07, validation loss 5.022807840759924e-07\n",
      "epoch 314000, training loss 1.1227019314219433e-08, validation loss 5.336974240321979e-08\n",
      "(--> new model saved @ epoch 314000)\n",
      "epoch 315000, training loss 2.9647775789953812e-08, validation loss 7.646099930980199e-08\n",
      "epoch 316000, training loss 8.084354874426936e-08, validation loss 1.1723331283519656e-07\n",
      "epoch 317000, training loss 1.6522891499448633e-08, validation loss 5.9589979173324537e-08\n",
      "epoch 318000, training loss 1.1686407930255882e-07, validation loss 1.5539141884346463e-07\n",
      "epoch 319000, training loss 1.9570397569168563e-07, validation loss 2.250223190003453e-07\n",
      "epoch 320000, training loss 9.769314601726364e-07, validation loss 9.89121417660499e-07\n",
      "epoch 321000, training loss 1.4451092766876172e-08, validation loss 5.786253254314033e-08\n",
      "epoch 322000, training loss 3.9156844877652475e-07, validation loss 4.6555740595977113e-07\n",
      "epoch 323000, training loss 1.6011514958336193e-07, validation loss 2.0506398357156286e-07\n",
      "epoch 324000, training loss 3.442892548832788e-08, validation loss 7.112107169859883e-08\n",
      "epoch 325000, training loss 3.152413086127126e-08, validation loss 6.937699481568416e-08\n",
      "epoch 326000, training loss 3.3961764955847684e-08, validation loss 7.733719087354984e-08\n",
      "epoch 327000, training loss 4.8762657911538554e-08, validation loss 9.262444677915482e-08\n",
      "epoch 328000, training loss 1.2474716015731246e-07, validation loss 1.7314006584001618e-07\n",
      "epoch 329000, training loss 3.3102156749009737e-07, validation loss 3.7745445524706156e-07\n",
      "epoch 330000, training loss 2.1424024509997253e-07, validation loss 2.347026395455032e-07\n",
      "epoch 331000, training loss 1.6218084653019105e-08, validation loss 5.6178695473363405e-08\n",
      "epoch 332000, training loss 1.5300958011721377e-07, validation loss 2.015885200989942e-07\n",
      "epoch 333000, training loss 2.317620939606968e-08, validation loss 6.951442088620752e-08\n",
      "epoch 334000, training loss 3.4979387919520377e-07, validation loss 3.9320744349424785e-07\n",
      "epoch 335000, training loss 6.164097499095078e-07, validation loss 6.592639465452521e-07\n",
      "epoch 336000, training loss 3.594113451299563e-08, validation loss 7.26044859788999e-08\n",
      "epoch 337000, training loss 9.447424531572324e-08, validation loss 1.3042401292295835e-07\n",
      "epoch 338000, training loss 4.7980201145492174e-08, validation loss 7.946105995415564e-08\n",
      "epoch 339000, training loss 4.7685379200856914e-08, validation loss 9.041831106060272e-08\n",
      "epoch 340000, training loss 2.1808086785313208e-06, validation loss 2.1361454400903312e-06\n",
      "epoch 341000, training loss 2.9413330437932927e-08, validation loss 6.433236166003553e-08\n",
      "epoch 342000, training loss 4.357802296794944e-08, validation loss 9.836956138542519e-08\n",
      "epoch 343000, training loss 2.657020203855609e-08, validation loss 6.689886333788309e-08\n",
      "epoch 344000, training loss 9.553471613799047e-08, validation loss 1.3088289563256694e-07\n",
      "epoch 345000, training loss 2.3988349084902438e-08, validation loss 7.240555532916915e-08\n",
      "epoch 346000, training loss 1.2389318726491183e-07, validation loss 1.520572396884745e-07\n",
      "epoch 347000, training loss 5.734599639595217e-08, validation loss 1.0926667215471753e-07\n",
      "epoch 348000, training loss 8.402306406196658e-08, validation loss 1.1441995440009123e-07\n",
      "epoch 349000, training loss 2.0746654172398848e-07, validation loss 2.3090115064405836e-07\n",
      "epoch 350000, training loss 7.72541426385942e-08, validation loss 1.2756026990246028e-07\n",
      "epoch 351000, training loss 1.4906302681083616e-07, validation loss 1.7862295464965428e-07\n",
      "epoch 352000, training loss 9.545001233846051e-08, validation loss 1.2651325675960834e-07\n",
      "epoch 353000, training loss 8.92337581603897e-08, validation loss 1.4580248830498022e-07\n",
      "epoch 354000, training loss 2.3054962383639577e-08, validation loss 6.653683470858596e-08\n",
      "epoch 355000, training loss 8.398777850970873e-08, validation loss 1.2442221475339466e-07\n",
      "epoch 356000, training loss 1.1251193399175463e-07, validation loss 1.5118531848656858e-07\n",
      "epoch 357000, training loss 5.722392870666226e-07, validation loss 5.798515303467866e-07\n",
      "epoch 358000, training loss 3.6483808685261465e-07, validation loss 4.036365908177686e-07\n",
      "epoch 359000, training loss 1.088312231445343e-07, validation loss 1.3734704396028974e-07\n",
      "epoch 360000, training loss 1.710037764723893e-07, validation loss 2.255540323403693e-07\n",
      "epoch 361000, training loss 9.687103101896355e-07, validation loss 1.0292471870343434e-06\n",
      "epoch 362000, training loss 3.0574675236039184e-08, validation loss 7.39173628971912e-08\n",
      "epoch 363000, training loss 3.725281416677717e-08, validation loss 7.786672995280242e-08\n",
      "epoch 364000, training loss 2.4151844968400837e-08, validation loss 5.829067717399994e-08\n",
      "epoch 365000, training loss 6.167658170852519e-07, validation loss 6.320332204268198e-07\n",
      "epoch 366000, training loss 5.629087596048521e-08, validation loss 8.675704066263279e-08\n",
      "epoch 367000, training loss 4.3690988604794256e-08, validation loss 8.728753186915128e-08\n",
      "epoch 368000, training loss 2.75187801435095e-07, validation loss 3.093804821219237e-07\n",
      "epoch 369000, training loss 6.706118682586748e-08, validation loss 1.0303774189424075e-07\n",
      "epoch 370000, training loss 4.0975404402843196e-08, validation loss 7.900062115595574e-08\n",
      "epoch 371000, training loss 9.4930250327252e-08, validation loss 1.219428753529428e-07\n",
      "epoch 372000, training loss 1.1531673038689405e-07, validation loss 1.5297911204470438e-07\n",
      "epoch 373000, training loss 3.4464937925804406e-07, validation loss 3.9268152818294766e-07\n",
      "epoch 374000, training loss 3.0751178314858407e-07, validation loss 3.812244528944575e-07\n",
      "epoch 375000, training loss 7.789812883629565e-08, validation loss 1.0707013586852554e-07\n",
      "epoch 376000, training loss 1.494161239179448e-08, validation loss 5.253797041859798e-08\n",
      "(--> new model saved @ epoch 376000)\n",
      "epoch 377000, training loss 6.158759191521312e-08, validation loss 1.0679374184974222e-07\n",
      "epoch 378000, training loss 3.2912052461142594e-07, validation loss 3.530029744069907e-07\n",
      "epoch 379000, training loss 2.5812274984104988e-08, validation loss 6.946007147234923e-08\n",
      "epoch 380000, training loss 4.140900102811429e-07, validation loss 4.4283521560828376e-07\n",
      "epoch 381000, training loss 3.234872636426189e-08, validation loss 6.784619444033524e-08\n",
      "epoch 382000, training loss 2.2249498243809285e-08, validation loss 6.724615531084055e-08\n",
      "epoch 383000, training loss 1.6577980943566217e-07, validation loss 1.975521399799618e-07\n",
      "epoch 384000, training loss 5.533555835768311e-08, validation loss 1.0657858950935406e-07\n",
      "epoch 385000, training loss 3.1459698845992534e-08, validation loss 7.455822981228266e-08\n",
      "epoch 386000, training loss 4.172939611635229e-07, validation loss 4.3976103825116297e-07\n",
      "epoch 387000, training loss 2.3104675506147032e-08, validation loss 6.124857065969991e-08\n",
      "epoch 388000, training loss 1.422576048071278e-07, validation loss 1.7242867045297317e-07\n",
      "epoch 389000, training loss 2.8739020052626074e-08, validation loss 6.31106402693149e-08\n",
      "epoch 390000, training loss 1.1180186554327065e-08, validation loss 5.250588230865105e-08\n",
      "(--> new model saved @ epoch 390000)\n",
      "epoch 391000, training loss 6.128340857003423e-08, validation loss 1.0232375302621222e-07\n",
      "epoch 392000, training loss 2.2785238584788203e-08, validation loss 6.457884182964335e-08\n",
      "epoch 393000, training loss 7.26186669908202e-07, validation loss 7.813462730155152e-07\n",
      "epoch 394000, training loss 4.834734568248678e-07, validation loss 4.984316888112517e-07\n",
      "epoch 395000, training loss 2.9350047725529294e-07, validation loss 3.3067661320274055e-07\n",
      "epoch 396000, training loss 3.8508851218921336e-08, validation loss 8.039898347078633e-08\n",
      "epoch 397000, training loss 2.1662945925982058e-07, validation loss 2.6041581691060856e-07\n",
      "epoch 398000, training loss 1.1121535692382167e-07, validation loss 1.5618537929640297e-07\n",
      "epoch 399000, training loss 2.2746796446426742e-07, validation loss 2.7017512138627353e-07\n",
      "epoch 400000, training loss 9.986204929646192e-08, validation loss 1.3634748086133186e-07\n",
      "epoch 401000, training loss 1.4790751379223366e-07, validation loss 1.8085810893353482e-07\n",
      "epoch 402000, training loss 1.3226568285062967e-07, validation loss 1.6811704028896202e-07\n",
      "epoch 403000, training loss 1.635343522821131e-07, validation loss 2.1436643748984352e-07\n",
      "epoch 404000, training loss 9.511096976666522e-08, validation loss 1.4525247138408304e-07\n",
      "epoch 405000, training loss 1.179791411232145e-07, validation loss 1.8361028253366385e-07\n",
      "epoch 406000, training loss 2.597274040283537e-08, validation loss 6.544597397351026e-08\n",
      "epoch 407000, training loss 1.698998630672577e-08, validation loss 5.993422291794559e-08\n",
      "epoch 408000, training loss 4.660311105908477e-07, validation loss 4.901355055153545e-07\n",
      "epoch 409000, training loss 1.8215505548369038e-08, validation loss 5.5976613566599553e-08\n",
      "epoch 410000, training loss 2.2490318940526777e-08, validation loss 5.9572212052216855e-08\n",
      "epoch 411000, training loss 6.903768934307664e-08, validation loss 1.0922899917886753e-07\n",
      "epoch 412000, training loss 1.298522889214837e-08, validation loss 5.1505423925846117e-08\n",
      "(--> new model saved @ epoch 412000)\n",
      "epoch 413000, training loss 8.667458928357519e-08, validation loss 1.197597470081746e-07\n",
      "epoch 414000, training loss 2.8252881634216465e-07, validation loss 3.418224707729678e-07\n",
      "epoch 415000, training loss 5.737852006859612e-07, validation loss 6.003404564580705e-07\n",
      "epoch 416000, training loss 2.3125021186842787e-07, validation loss 2.838438604158e-07\n",
      "epoch 417000, training loss 1.7677207253541383e-08, validation loss 5.5871314685873585e-08\n",
      "epoch 418000, training loss 1.5963129484930505e-08, validation loss 5.380764278584138e-08\n",
      "epoch 419000, training loss 2.1350156487187633e-07, validation loss 2.7371712008061877e-07\n",
      "epoch 420000, training loss 1.1155921697536542e-07, validation loss 1.4520661295591708e-07\n",
      "epoch 421000, training loss 7.113359146160292e-08, validation loss 1.1066995142527958e-07\n",
      "epoch 422000, training loss 2.6614888071208043e-08, validation loss 6.533735330549462e-08\n",
      "epoch 423000, training loss 1.0678520112605838e-07, validation loss 1.474352018249192e-07\n",
      "epoch 424000, training loss 1.6326833218727188e-08, validation loss 5.745991771277659e-08\n",
      "epoch 425000, training loss 5.580978950092685e-07, validation loss 6.027587460266659e-07\n",
      "epoch 426000, training loss 1.8730816009338014e-08, validation loss 5.346644726955674e-08\n",
      "epoch 427000, training loss 2.7183020279153425e-07, validation loss 2.9838977866347705e-07\n",
      "epoch 428000, training loss 1.5475681891530257e-07, validation loss 1.9529950634478155e-07\n",
      "epoch 429000, training loss 2.1939662531167414e-07, validation loss 2.6882068482336763e-07\n",
      "epoch 430000, training loss 1.3947691002158535e-07, validation loss 1.594451504161043e-07\n",
      "epoch 431000, training loss 1.7078620828669955e-07, validation loss 2.1558085450124054e-07\n",
      "epoch 432000, training loss 8.740022039432915e-09, validation loss 4.8891259041283774e-08\n",
      "(--> new model saved @ epoch 432000)\n",
      "epoch 433000, training loss 1.4304979423229724e-08, validation loss 5.070517872240998e-08\n",
      "epoch 434000, training loss 1.4615442189835903e-08, validation loss 5.107339617893558e-08\n",
      "epoch 435000, training loss 2.0629999042398595e-08, validation loss 5.48743841477517e-08\n",
      "epoch 436000, training loss 5.05744424117438e-08, validation loss 8.861844236207617e-08\n",
      "epoch 437000, training loss 1.7131094764977206e-08, validation loss 5.377508571768885e-08\n",
      "epoch 438000, training loss 2.3909794322207745e-07, validation loss 2.8670729079749435e-07\n",
      "epoch 439000, training loss 1.6408876035711728e-07, validation loss 2.1468319744144537e-07\n",
      "epoch 440000, training loss 4.0163453007835415e-08, validation loss 7.437953541966635e-08\n",
      "epoch 441000, training loss 1.2490397693909472e-07, validation loss 1.7716989475502487e-07\n",
      "epoch 442000, training loss 1.1438267932817325e-07, validation loss 1.4933394254512677e-07\n",
      "epoch 443000, training loss 1.1524404541773947e-08, validation loss 5.059586172251329e-08\n",
      "epoch 444000, training loss 6.157905829695665e-08, validation loss 8.908191517775776e-08\n",
      "epoch 445000, training loss 1.0781619153021893e-07, validation loss 1.6037317607242585e-07\n",
      "epoch 446000, training loss 3.494356803912524e-08, validation loss 7.545126123886803e-08\n",
      "epoch 447000, training loss 2.5843700512950818e-08, validation loss 6.740246050185306e-08\n",
      "epoch 448000, training loss 2.1319293352917157e-07, validation loss 2.582172839993291e-07\n",
      "epoch 449000, training loss 1.8326725026440727e-08, validation loss 5.979708816994389e-08\n",
      "epoch 450000, training loss 2.320943970346434e-08, validation loss 5.637173217110103e-08\n",
      "epoch 451000, training loss 2.2739963867479673e-07, validation loss 2.8507335514404986e-07\n",
      "epoch 452000, training loss 7.991314987521037e-08, validation loss 1.133928151375585e-07\n",
      "epoch 453000, training loss 8.970925335916036e-08, validation loss 1.3599644432815694e-07\n",
      "epoch 454000, training loss 2.851866724995489e-07, validation loss 3.226822116175754e-07\n",
      "epoch 455000, training loss 2.0532645805815264e-07, validation loss 2.4758770678090514e-07\n",
      "epoch 456000, training loss 1.3157505307503925e-08, validation loss 5.553181736672741e-08\n",
      "epoch 457000, training loss 6.397872880370414e-07, validation loss 7.080164436956693e-07\n",
      "epoch 458000, training loss 6.572201982635306e-08, validation loss 1.0919833215439212e-07\n",
      "epoch 459000, training loss 6.126285967411604e-08, validation loss 9.01296317579181e-08\n",
      "epoch 460000, training loss 3.856431618487477e-08, validation loss 7.530438494995906e-08\n",
      "epoch 461000, training loss 8.553097785579666e-08, validation loss 1.2147459926836746e-07\n",
      "epoch 462000, training loss 1.660100821254673e-07, validation loss 2.1067131683594198e-07\n",
      "epoch 463000, training loss 1.1426998014485434e-08, validation loss 5.184438833794047e-08\n",
      "epoch 464000, training loss 1.97347247876678e-07, validation loss 2.530320557525556e-07\n",
      "epoch 465000, training loss 4.291153743452014e-07, validation loss 4.979295908924541e-07\n",
      "epoch 466000, training loss 4.253491070471682e-08, validation loss 7.473843766092614e-08\n",
      "epoch 467000, training loss 1.9435947251622565e-07, validation loss 2.474000382335362e-07\n",
      "epoch 468000, training loss 8.787193905845925e-08, validation loss 1.293336140406609e-07\n",
      "epoch 469000, training loss 6.381366688401613e-07, validation loss 6.641709546784114e-07\n",
      "epoch 470000, training loss 7.139913549281118e-08, validation loss 1.2380429836866824e-07\n",
      "epoch 471000, training loss 1.2141110516949993e-07, validation loss 1.629192496466203e-07\n",
      "epoch 472000, training loss 3.172327822653642e-08, validation loss 6.844982181064552e-08\n",
      "epoch 473000, training loss 9.518765331506529e-09, validation loss 4.847612089520226e-08\n",
      "(--> new model saved @ epoch 473000)\n",
      "epoch 474000, training loss 1.1109538178288858e-08, validation loss 5.1331870309923033e-08\n",
      "epoch 475000, training loss 9.240800835641494e-08, validation loss 1.285296917785672e-07\n",
      "epoch 476000, training loss 2.9947500479465816e-08, validation loss 7.306509530735639e-08\n",
      "epoch 477000, training loss 2.879243865550052e-08, validation loss 6.391490359192176e-08\n",
      "epoch 478000, training loss 2.8728855738791026e-08, validation loss 6.514014927461176e-08\n",
      "epoch 479000, training loss 7.276647551179849e-08, validation loss 1.1051651682691954e-07\n",
      "epoch 480000, training loss 3.58091831742513e-08, validation loss 7.431030724092125e-08\n",
      "epoch 481000, training loss 1.721057785175617e-08, validation loss 5.565242844340901e-08\n",
      "epoch 482000, training loss 3.3531068766023964e-07, validation loss 4.126032138174196e-07\n",
      "epoch 483000, training loss 1.9223661240630463e-07, validation loss 2.399697791588551e-07\n",
      "epoch 484000, training loss 2.213512217963398e-08, validation loss 6.040997391210112e-08\n",
      "epoch 485000, training loss 1.7519016637379536e-06, validation loss 1.7264696907659527e-06\n",
      "epoch 486000, training loss 7.24296285170567e-08, validation loss 1.1705805746942133e-07\n",
      "epoch 487000, training loss 1.6249002783297328e-06, validation loss 1.6766056205597124e-06\n",
      "epoch 488000, training loss 7.094363922988123e-07, validation loss 7.391196277239942e-07\n",
      "epoch 489000, training loss 2.3507716662152234e-07, validation loss 2.7065422614214185e-07\n",
      "epoch 490000, training loss 3.432631501709693e-06, validation loss 3.4244258131366223e-06\n",
      "epoch 491000, training loss 6.106351690959855e-08, validation loss 9.476012508002896e-08\n",
      "epoch 492000, training loss 1.4550533933288534e-07, validation loss 1.8413086877444584e-07\n",
      "epoch 493000, training loss 6.088289978833927e-07, validation loss 6.120037596701877e-07\n",
      "epoch 494000, training loss 6.571416832912291e-08, validation loss 9.765590647248246e-08\n",
      "epoch 495000, training loss 7.980244731697894e-08, validation loss 1.278272634408495e-07\n",
      "epoch 496000, training loss 3.0844553577935585e-08, validation loss 6.763661275499544e-08\n",
      "epoch 497000, training loss 1.2057687293065555e-08, validation loss 4.953633236937094e-08\n",
      "epoch 498000, training loss 1.1899585317109995e-08, validation loss 4.848762458209421e-08\n",
      "epoch 499000, training loss 1.8465787121613175e-08, validation loss 5.383155610161339e-08\n",
      "epoch 500000, training loss 3.9948218955032644e-07, validation loss 4.5708065954386257e-07\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_D{}_noise{}.pt'.format(step_size, noise)\n",
    "\n",
    "# create/load model object\n",
    "try:\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = torch.load(os.path.join(model_dir, model_name), map_location=device)\n",
    "    model.device = device\n",
    "except:\n",
    "    print('create model {} ...'.format(model_name))\n",
    "    model = net.ResNet(arch=arch, dt=dt, step_size=step_size)\n",
    "\n",
    "# training\n",
    "model.train_net(dataset, max_epoch=max_epoch, batch_size=batch_size, lr=lr,\n",
    "                model_path=os.path.join(model_dir, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3710jvsc74a57bd00d235557d0feb0efea5d5740b2690d48a2120004fe3a587911c97a32194e2c15",
   "display_name": "Python 3.7.10 64-bit ('temp': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}