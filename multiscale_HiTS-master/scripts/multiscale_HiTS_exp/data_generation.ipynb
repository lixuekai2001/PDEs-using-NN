{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### created by Yuying Liu, 04/30/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is used for generating data sets for multiscale HiTS experiments. Here, we consider 5 nonlinear systems: a hyperbolic fixed point, a damped cubic oscillator, the Van der Pol oscillator, a Hopf normal form, and the Lorenz system. Simulations are conducted using scipy.integrate.solve_ivp() and considered as ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import integrate\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data/Hyperbolic\n"
     ]
    }
   ],
   "source": [
    "# paths\n",
    "data_dir = 'data/'\n",
    "hyperbolic_dir = os.path.join(data_dir, 'Hyperbolic')\n",
    "# cubic_dir = os.path.join(data_dir, 'Cubic')\n",
    "# vdp_dir = os.path.join(data_dir, 'VanDerPol')\n",
    "# hopf_dir = os.path.join(data_dir, 'Hopf')\n",
    "# lorenz_dir = os.path.join(data_dir, 'Lorenz')\n",
    "print(hyperbolic_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "../../data/Hyperbolic/Cubic\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../../data/'\n",
    "hyperbolic_dir = os.path.join(data_dir, 'Hyperbolic/')\n",
    "# cubic_dir = os.path.join(hyperbolic_dir, 'Cubic')\n",
    "print(cubic_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjustable parameters\n",
    "dt = 0.01       # set to 5e-4 for Lorenz\n",
    "noise = 0.      # for study of noisy measurements, we use noise=0.01, 0.02; otherwise we leave it as 0.\n",
    "n_forward = 5\n",
    "total_steps = 1024 * n_forward\n",
    "t = np.linspace(0, (total_steps)*dt, total_steps+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperbolic fixed point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "    \\dot{x} &= \\mu x \\\\\n",
    "    \\dot{y} &= \\lambda(y-x^2)     \n",
    "\\end{split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "mu = -0.05\n",
    "lam = -1.0\n",
    "def hyperbolic_rhs(x):\n",
    "    return np.array([mu*x[0], lam*(x[1]-x[0]**2)])\n",
    "\n",
    "# simulation parameters\n",
    "np.random.seed(2)\n",
    "n = 2\n",
    "\n",
    "# dataset \n",
    "n_train = 1600\n",
    "n_val = 320\n",
    "n_test = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "generating training trials ...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/1600 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f54422c541b4e7d92bba1284194c0ee"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "generating validation trials ...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/320 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89932439b3074efcb385839e87588f16"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "generating testing trials ...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/320 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59fbeb222df44dce9c2c2f48840246be"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# simulate training trials \n",
    "train_data = np.zeros((n_train, total_steps+1, n))\n",
    "print('generating training trials ...')\n",
    "for i in tqdm(range(n_train)):\n",
    "    x_init = np.random.uniform(-1.0, 1.0, n)\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: hyperbolic_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    train_data[i, :, :] = sol.y.T\n",
    "\n",
    "# simulate validation trials \n",
    "val_data = np.zeros((n_val, total_steps+1, n))\n",
    "print('generating validation trials ...')\n",
    "for i in tqdm(range(n_val)):\n",
    "    x_init = np.random.uniform(-1.0, 1.0, n)\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: hyperbolic_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    val_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# simulate test trials\n",
    "test_data = np.zeros((n_test, total_steps+1, n))\n",
    "print('generating testing trials ...')\n",
    "for i in tqdm(range(n_test)):\n",
    "    x_init = np.random.uniform(-1.0, 1.0, n)\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: hyperbolic_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    test_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# add noise\n",
    "train_data += noise*train_data.std(1).mean(0)*np.random.randn(*train_data.shape)\n",
    "val_data += noise*val_data.std(1).mean(0)*np.random.randn(*val_data.shape)\n",
    "test_data += noise*test_data.std(1).mean(0)*np.random.randn(*test_data.shape)\n",
    "        \n",
    "# save data\n",
    "np.save(os.path.join(hyperbolic_dir, 'train_noise{}.npy'.format(noise)), train_data)\n",
    "np.save(os.path.join(hyperbolic_dir, 'val_noise{}.npy'.format(noise)), val_data)\n",
    "np.save(os.path.join(hyperbolic_dir, 'test_noise{}.npy'.format(noise)), test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cubic oscillator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "    \\dot{x} &= -0.1x^3 + 2y^3 \\\\\n",
    "    \\dot{y} &= -2x^3 - 0.1y^3\n",
    "\\end{split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "def cubic_rhs(x):\n",
    "    return np.array([-0.1*x[0]**3+2*x[1]**3, \n",
    "                     -2*x[0]**3-0.1*x[1]**3])\n",
    "\n",
    "# simulation parameters\n",
    "np.random.seed(2)\n",
    "n = 2\n",
    "\n",
    "# dataset \n",
    "n_train = 3200\n",
    "n_val = 320\n",
    "n_test = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate training trials \n",
    "train_data = np.zeros((n_train, total_steps+1, n))\n",
    "print('generating training trials ...')\n",
    "for i in tqdm(range(n_train)):\n",
    "    x_init = np.random.uniform(-1.0, 1.0, n)\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: cubic_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    train_data[i, :, :] = sol.y.T\n",
    "\n",
    "# simulate validation trials \n",
    "val_data = np.zeros((n_val, total_steps+1, n))\n",
    "print('generating validation trials ...')\n",
    "for i in tqdm(range(n_val)):\n",
    "    x_init = np.random.uniform(-1.0, 1.0, n)\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: cubic_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    val_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# simulate test trials\n",
    "test_data = np.zeros((n_test, total_steps+1, n))\n",
    "print('generating testing trials ...')\n",
    "for i in tqdm(range(n_test)):\n",
    "    x_init = np.random.uniform(-1.0, 1.0, n)\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: cubic_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    test_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# add noise\n",
    "train_data += noise*train_data.std(1).mean(0)*np.random.randn(*train_data.shape)\n",
    "val_data += noise*val_data.std(1).mean(0)*np.random.randn(*val_data.shape)\n",
    "test_data += noise*test_data.std(1).mean(0)*np.random.randn(*test_data.shape)    \n",
    "\n",
    "# save data\n",
    "np.save(os.path.join(cubic_dir, 'train_noise{}.npy'.format(noise)), train_data)\n",
    "np.save(os.path.join(cubic_dir, 'val_noise{}.npy'.format(noise)), val_data)\n",
    "np.save(os.path.join(cubic_dir, 'test_noise{}.npy'.format(noise)), test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Van der Pol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "    \\dot{x} &= y \\\\\n",
    "    \\dot{y} &= \\mu(1-x^2)y - x   \n",
    "\\end{split}\n",
    "\n",
    "where $\\mu=2.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "mu = 2.0\n",
    "def van_der_pol_rhs(x):\n",
    "    return np.array([x[1], mu*(1-x[0]**2)*x[1]-x[0]])\n",
    "\n",
    "# simulation parameters\n",
    "np.random.seed(2)\n",
    "n = 2\n",
    "\n",
    "# dataset \n",
    "n_train = 3200\n",
    "n_val = 320\n",
    "n_test = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate training trials \n",
    "train_data = np.zeros((n_train, total_steps+1, n))\n",
    "print('generating training trials ...')\n",
    "for i in tqdm(range(n_train)):\n",
    "    x_init = [np.random.uniform(-2.0, 2.0), np.random.uniform(-4.0, 4.0)]\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: van_der_pol_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    train_data[i, :, :] = sol.y.T\n",
    "\n",
    "# simulate validation trials \n",
    "val_data = np.zeros((n_val, total_steps+1, n))\n",
    "print('generating validation trials ...')\n",
    "for i in tqdm(range(n_val)):\n",
    "    x_init = [np.random.uniform(-2.0, 2.0), np.random.uniform(-2.0, 2.0)]    # make sure we have seen them in training set\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: van_der_pol_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    val_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# simulate test trials\n",
    "test_data = np.zeros((n_test, total_steps+1, n))\n",
    "print('generating testing trials ...')\n",
    "for i in tqdm(range(n_test)):\n",
    "    x_init = [np.random.uniform(-2.0, 2.0), np.random.uniform(-2.0, 2.0)]\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: van_der_pol_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    test_data[i, :, :] = sol.y.T\n",
    "        \n",
    "# add noise\n",
    "train_data += noise*train_data.std(1).mean(0)*np.random.randn(*train_data.shape)\n",
    "val_data += noise*val_data.std(1).mean(0)*np.random.randn(*val_data.shape)\n",
    "test_data += noise*test_data.std(1).mean(0)*np.random.randn(*test_data.shape)\n",
    "        \n",
    "# save data\n",
    "np.save(os.path.join(vdp_dir, 'train_noise{}.npy'.format(noise)), train_data)\n",
    "np.save(os.path.join(vdp_dir, 'val_noise{}.npy'.format(noise)), val_data)\n",
    "np.save(os.path.join(vdp_dir, 'test_noise{}.npy'.format(noise)), test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hopf bifurcation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "    \\dot{\\mu} &= 0 \\\\\n",
    "    \\dot{x} &= \\mu x + y -x(x^2+y^2) \\\\\n",
    "    \\dot{y} &= \\mu y - x -y(x^2+y^2)\n",
    "\\end{split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "def hopf_rhs(x):\n",
    "    return np.array([0, x[0]*x[1]+x[2]-x[1]*(x[1]**2+x[2]**2),\n",
    "                    -x[1]+x[0]*x[2]-x[2]*(x[1]**2+x[2]**2)])\n",
    "\n",
    "# simulation parameters\n",
    "np.random.seed(2)\n",
    "n = 3\n",
    "\n",
    "# dataset \n",
    "n_train = 3200\n",
    "n_val = 320\n",
    "n_test = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate training trials \n",
    "train_data = np.zeros((n_train, total_steps+1, n))\n",
    "print('generating training trials ...')\n",
    "for i in tqdm(range(n_train)):\n",
    "    x_init = [np.random.uniform(-0.2, 0.6), np.random.uniform(-1, 2), np.random.uniform(-1, 1)]\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: hopf_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    train_data[i, :, :] = sol.y.T\n",
    "\n",
    "# simulate validation trials \n",
    "val_data = np.zeros((n_val, total_steps+1, n))\n",
    "print('generating validation trials ...')\n",
    "for i in tqdm(range(n_val)):\n",
    "    x_init = [np.random.uniform(-0.2, 0.6), np.random.uniform(-1, 2), np.random.uniform(-1, 1)]\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: hopf_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    val_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# simulate test trials\n",
    "test_data = np.zeros((n_test, total_steps+1, n))\n",
    "print('generating testing trials ...')\n",
    "for i in tqdm(range(n_test)):\n",
    "    x_init = [np.random.uniform(-0.2, 0.6), np.random.uniform(-1, 2), np.random.uniform(-1, 1)]\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: hopf_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    test_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# add noise\n",
    "train_data += noise*train_data.std(1).mean(0)*np.random.randn(*train_data.shape)\n",
    "val_data += noise*val_data.std(1).mean(0)*np.random.randn(*val_data.shape)\n",
    "test_data += noise*test_data.std(1).mean(0)*np.random.randn(*test_data.shape)\n",
    "        \n",
    "# save data\n",
    "np.save(os.path.join(hopf_dir, 'train_noise{}.npy'.format(noise)), train_data)\n",
    "np.save(os.path.join(hopf_dir, 'val_noise{}.npy'.format(noise)), val_data)\n",
    "np.save(os.path.join(hopf_dir, 'test_noise{}.npy'.format(noise)), test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lorenz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "    \\dot{x} &= \\sigma(y-x) \\\\\n",
    "    \\dot{y} &= x(\\rho-z)-y \\\\\n",
    "    \\dot{z} &= xy - \\beta z    \n",
    "\\end{split}\n",
    "\n",
    "where $\\sigma=10, \\rho=28, \\beta=8/3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "sigma = 10\n",
    "rho = 28\n",
    "beta = 8/3\n",
    "    \n",
    "def lorenz_rhs(x):\n",
    "    return np.array([sigma*(x[1]-x[0]), x[0]*(rho-x[2])-x[1], x[0]*x[1]-beta*x[2]])\n",
    "\n",
    "# simulation parameters\n",
    "np.random.seed(2)\n",
    "warmup = 10000\n",
    "n = 3\n",
    "\n",
    "# dataset \n",
    "n_train = 6400\n",
    "n_val = 640\n",
    "n_test = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate training trials \n",
    "pre_t = np.linspace(0, warmup*dt, warmup+1)\n",
    "\n",
    "train_data = np.zeros((n_train, total_steps+1, n))\n",
    "print('generating training trials ...')\n",
    "x_init = np.random.uniform(-0.1, 0.1, n)\n",
    "sol = sp.integrate.solve_ivp(lambda _, x: lorenz_rhs(x), [0, warmup*dt], x_init, t_eval=pre_t)\n",
    "for i in tqdm(range(n_train)):\n",
    "    x_init = sol.y[:, -1].T\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: lorenz_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    train_data[i, :, :] = sol.y.T\n",
    "\n",
    "# simulate validation trials \n",
    "val_data = np.zeros((n_val, total_steps+1, n))\n",
    "print('generating validation trials ...')\n",
    "x_init = np.random.uniform(-0.1, 0.1, n)\n",
    "sol = sp.integrate.solve_ivp(lambda _, x: lorenz_rhs(x), [0, warmup*dt], x_init, t_eval=pre_t)\n",
    "for i in tqdm(range(n_val)):\n",
    "    x_init = sol.y[:, -1].T    \n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: lorenz_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    val_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# simulate test trials\n",
    "test_data = np.zeros((n_test, total_steps+1, n))\n",
    "print('generating testing trials ...')\n",
    "x_init = np.random.uniform(-0.1, 0.1, n)\n",
    "sol = sp.integrate.solve_ivp(lambda _, x: lorenz_rhs(x), [0, warmup*dt], x_init, t_eval=pre_t)\n",
    "for i in tqdm(range(n_test)):\n",
    "    x_init = sol.y[:, -1].T\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: lorenz_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    test_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# add noise\n",
    "train_data += noise*train_data.std(1).mean(0)*np.random.randn(*train_data.shape)\n",
    "val_data += noise*val_data.std(1).mean(0)*np.random.randn(*val_data.shape)\n",
    "test_data += noise*test_data.std(1).mean(0)*np.random.randn(*test_data.shape)\n",
    "        \n",
    "# save data\n",
    "np.save(os.path.join(lorenz_dir, 'train_noise{}.npy'.format(noise)), train_data)\n",
    "np.save(os.path.join(lorenz_dir, 'val_noise{}.npy'.format(noise)), val_data)\n",
    "np.save(os.path.join(lorenz_dir, 'test_noise{}.npy'.format(noise)), test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3710jvsc74a57bd00d235557d0feb0efea5d5740b2690d48a2120004fe3a587911c97a32194e2c15",
   "display_name": "Python 3.7.10 64-bit ('temp': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "17a72e36a438a71ffc56163934110da7392f08a4bdbb1baa283e376eb1ee47cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}