{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### created by Yuying Liu, 04/30/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is used for generating training, validating, testdata sets for multiscale HiTS experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import integrate\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shared parameters (adjustables)\n",
    "dt = 0.01   # set to 1e-3 for Lorenz\n",
    "n_forward = 5\n",
    "total_steps = 1024 * n_forward\n",
    "t = np.linspace(0, (total_steps)*dt, total_steps+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperbolic fixed point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "    \\dot{x} &= \\mu x \\\\\n",
    "    \\dot{y} &= \\lambda(y-x^2)     \n",
    "\\end{split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "data_dir = '../../data/VaryingStep/Hyperbolic/'\n",
    "\n",
    "# system\n",
    "mu = -0.05\n",
    "lam = -1.0\n",
    "def hyperbolic_rhs(x):\n",
    "    return np.array([mu*x[0], lam*(x[1]-x[0]**2)])\n",
    "\n",
    "# simulation parameters\n",
    "np.random.seed(2)\n",
    "n = 2\n",
    "\n",
    "# dataset \n",
    "n_train = 500\n",
    "n_val = 100\n",
    "n_test = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate training trials \n",
    "train_data = np.zeros((n_train, total_steps+1, n))\n",
    "print('generating training trials ...')\n",
    "for i in tqdm(range(n_train)):\n",
    "    x_init = np.random.uniform(-1.0, 1.0, n)\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: hyperbolic_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    train_data[i, :, :] = sol.y.T\n",
    "\n",
    "# simulate validation trials \n",
    "val_data = np.zeros((n_val, total_steps+1, n))\n",
    "print('generating validation trials ...')\n",
    "for i in tqdm(range(n_val)):\n",
    "    x_init = np.random.uniform(-1.0, 1.0, n)\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: hyperbolic_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    val_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# simulate test trials\n",
    "test_data = np.zeros((n_test, total_steps+1, n))\n",
    "print('generating testing trials ...')\n",
    "for i in tqdm(range(n_test)):\n",
    "    x_init = np.random.uniform(-1.0, 1.0, n)\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: hyperbolic_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    test_data[i, :, :] = sol.y.T\n",
    "        \n",
    "# save data\n",
    "np.save(os.path.join(data_dir, 'trainBig.npy'), train_data)\n",
    "np.save(os.path.join(data_dir, 'valBig.npy'), val_data)\n",
    "np.save(os.path.join(data_dir, 'testBig.npy'), test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cubic oscillator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "    \\dot{x} &= -0.1x^3 + 2y^3 \\\\\n",
    "    \\dot{y} &= -2x^3 - 0.1y^3\n",
    "\\end{split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "data_dir = '../../data/VaryingStep/Cubic/'\n",
    "\n",
    "# system\n",
    "def cubic_rhs(x):\n",
    "    return np.array([-0.1*x[0]**3+2*x[1]**3, \n",
    "                     -2*x[0]**3-0.1*x[1]**3])\n",
    "\n",
    "# simulation parameters\n",
    "np.random.seed(2)\n",
    "n = 2\n",
    "\n",
    "# dataset \n",
    "n_train = 500\n",
    "n_val = 100\n",
    "n_test = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate training trials \n",
    "train_data = np.zeros((n_train, total_steps+1, n))\n",
    "print('generating training trials ...')\n",
    "for i in tqdm(range(n_train)):\n",
    "    x_init = np.random.uniform(-1.0, 1.0, n)\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: cubic_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    train_data[i, :, :] = sol.y.T\n",
    "\n",
    "# simulate validation trials \n",
    "val_data = np.zeros((n_val, total_steps+1, n))\n",
    "print('generating validation trials ...')\n",
    "for i in tqdm(range(n_val)):\n",
    "    x_init = np.random.uniform(-1.0, 1.0, n)\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: cubic_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    val_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# simulate test trials\n",
    "test_data = np.zeros((n_test, total_steps+1, n))\n",
    "print('generating testing trials ...')\n",
    "for i in tqdm(range(n_test)):\n",
    "    x_init = np.random.uniform(-1.0, 1.0, n)\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: cubic_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    test_data[i, :, :] = sol.y.T\n",
    "        \n",
    "# save data\n",
    "np.save(os.path.join(data_dir, 'trainBig.npy'), train_data)\n",
    "np.save(os.path.join(data_dir, 'valBig.npy'), val_data)\n",
    "np.save(os.path.join(data_dir, 'testBig.npy'), test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Van der Pol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "    \\dot{x} &= y \\\\\n",
    "    \\dot{y} &= \\mu(1-x^2)y - x   \n",
    "\\end{split}\n",
    "\n",
    "where $\\mu=2.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "data_dir = '../../data/VaryingStep/VanDerPol/'\n",
    "\n",
    "# system\n",
    "mu = 2.0\n",
    "def van_der_pol_rhs(x):\n",
    "    return np.array([x[1], mu*(1-x[0]**2)*x[1]-x[0]])\n",
    "\n",
    "# simulation parameters\n",
    "np.random.seed(2)\n",
    "n = 2\n",
    "\n",
    "# dataset \n",
    "n_train = 500\n",
    "n_val = 100\n",
    "n_test = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate training trials \n",
    "train_data = np.zeros((n_train, total_steps+1, n))\n",
    "print('generating training trials ...')\n",
    "for i in tqdm(range(n_train)):\n",
    "    x_init = [np.random.uniform(-2.0, 2.0), np.random.uniform(-4.0, 4.0)]\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: van_der_pol_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    train_data[i, :, :] = sol.y.T\n",
    "\n",
    "# simulate validation trials \n",
    "val_data = np.zeros((n_val, total_steps+1, n))\n",
    "print('generating validation trials ...')\n",
    "for i in tqdm(range(n_val)):\n",
    "    x_init = [np.random.uniform(-2.0, 2.0), np.random.uniform(-4.0, 4.0)]\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: van_der_pol_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    val_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# simulate test trials\n",
    "test_data = np.zeros((n_test, total_steps+1, n))\n",
    "print('generating testing trials ...')\n",
    "for i in tqdm(range(n_test)):\n",
    "    x_init = [np.random.uniform(-2.0, 2.0), np.random.uniform(-4.0, 4.0)]\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: van_der_pol_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    test_data[i, :, :] = sol.y.T\n",
    "        \n",
    "# save data\n",
    "np.save(os.path.join(data_dir, 'trainBig.npy'), train_data)\n",
    "np.save(os.path.join(data_dir, 'valBig.npy'), val_data)\n",
    "np.save(os.path.join(data_dir, 'testBig.npy'), test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hopf bifurcation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "    \\dot{\\mu} &= 0 \\\\\n",
    "    \\dot{x} &= \\mu x + y -x(x^2+y^2) \\\\\n",
    "    \\dot{y} &= \\mu y - x -y(x^2+y^2)\n",
    "\\end{split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "data_dir = '../../data/VaryingStep/Hopf/'\n",
    "\n",
    "# system\n",
    "def hopf_rhs(x):\n",
    "    return np.array([0, x[0]*x[1]+x[2]-x[1]*(x[1]**2+x[2]**2),\n",
    "                    -x[1]+x[0]*x[2]-x[2]*(x[1]**2+x[2]**2)])\n",
    "\n",
    "# simulation parameters\n",
    "np.random.seed(2)\n",
    "n = 3\n",
    "\n",
    "# dataset \n",
    "n_train = 500\n",
    "n_val = 100\n",
    "n_test = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate training trials \n",
    "train_data = np.zeros((n_train, total_steps+1, n))\n",
    "print('generating training trials ...')\n",
    "for i in tqdm(range(n_train)):\n",
    "    x_init = [np.random.uniform(-0.2, 0.6), np.random.uniform(-1, 2), np.random.uniform(-1, 1)]\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: hopf_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    train_data[i, :, :] = sol.y.T\n",
    "\n",
    "# simulate validation trials \n",
    "val_data = np.zeros((n_val, total_steps+1, n))\n",
    "print('generating validation trials ...')\n",
    "for i in tqdm(range(n_val)):\n",
    "    x_init = [np.random.uniform(-0.2, 0.6), np.random.uniform(-1, 2), np.random.uniform(-1, 1)]\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: hopf_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    val_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# simulate test trials\n",
    "test_data = np.zeros((n_test, total_steps+1, n))\n",
    "print('generating testing trials ...')\n",
    "for i in tqdm(range(n_test)):\n",
    "    x_init = [np.random.uniform(-0.2, 0.6), np.random.uniform(-1, 2), np.random.uniform(-1, 1)]\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: hopf_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    test_data[i, :, :] = sol.y.T\n",
    "        \n",
    "# save data\n",
    "np.save(os.path.join(data_dir, 'trainBig.npy'), train_data)\n",
    "np.save(os.path.join(data_dir, 'valBig.npy'), val_data)\n",
    "np.save(os.path.join(data_dir, 'testBig.npy'), test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lorenz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "    \\dot{x} &= \\sigma(y-x) \\\\\n",
    "    \\dot{y} &= x(\\rho-z)-y \\\\\n",
    "    \\dot{z} &= xy - \\beta z    \n",
    "\\end{split}\n",
    "\n",
    "where $\\sigma=10, \\rho=28, \\beta=8/3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "data_dir = '../../data/VaryingStep/Lorenz/'\n",
    "\n",
    "# system\n",
    "sigma = 10\n",
    "rho = 28\n",
    "beta = 8/3\n",
    "    \n",
    "def lorenz_rhs(x):\n",
    "    return np.array([sigma*(x[1]-x[0]), x[0]*(rho-x[2])-x[1], x[0]*x[1]-beta*x[2]])\n",
    "\n",
    "# simulation parameters\n",
    "np.random.seed(2)\n",
    "warmup = 1000\n",
    "n = 3\n",
    "\n",
    "# dataset \n",
    "n_train = 500\n",
    "n_val = 100\n",
    "n_test = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate training trials \n",
    "pre_t = np.linspace(0, warmup*dt, warmup+1)\n",
    "\n",
    "train_data = np.zeros((n_train, total_steps+1, n))\n",
    "print('generating training trials ...')\n",
    "x_init = np.random.uniform(-0.1, 0.1, n)\n",
    "sol = sp.integrate.solve_ivp(lambda _, x: lorenz_rhs(x), [0, warmup*dt], x_init, t_eval=pre_t)\n",
    "for i in tqdm(range(n_train)):\n",
    "    x_init = sol.y[:, -1].T\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: lorenz_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    train_data[i, :, :] = sol.y.T\n",
    "\n",
    "# simulate validation trials \n",
    "val_data = np.zeros((n_val, total_steps+1, n))\n",
    "print('generating validation trials ...')\n",
    "x_init = np.random.uniform(-0.1, 0.1, n)\n",
    "sol = sp.integrate.solve_ivp(lambda _, x: lorenz_rhs(x), [0, warmup*dt], x_init, t_eval=pre_t)\n",
    "for i in tqdm(range(n_val)):\n",
    "    x_init = sol.y[:, -1].T    \n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: lorenz_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    val_data[i, :, :] = sol.y.T\n",
    "    \n",
    "# simulate test trials\n",
    "test_data = np.zeros((n_test, total_steps+1, n))\n",
    "print('generating testing trials ...')\n",
    "x_init = np.random.uniform(-0.1, 0.1, n)\n",
    "sol = sp.integrate.solve_ivp(lambda _, x: lorenz_rhs(x), [0, warmup*dt], x_init, t_eval=pre_t)\n",
    "for i in tqdm(range(n_test)):\n",
    "    x_init = sol.y[:, -1].T\n",
    "    sol = sp.integrate.solve_ivp(lambda _, x: lorenz_rhs(x), [0, total_steps*dt], x_init, t_eval=t)\n",
    "    test_data[i, :, :] = sol.y.T\n",
    "        \n",
    "# save data\n",
    "np.save(os.path.join(data_dir, 'trainBig.npy'), train_data)\n",
    "np.save(os.path.join(data_dir, 'valBig.npy'), val_data)\n",
    "np.save(os.path.join(data_dir, 'testBig.npy'), test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
